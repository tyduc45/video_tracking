# æ–°æ¶æ„ï¼šå¤šè§†é¢‘æ‰¹å¤„ç†æ¨ç†ç³»ç»Ÿ

## ğŸ¯ æ¶æ„é©æ–°ç›®æ ‡

å°†æ—§æ–¹æ³•å’Œæ–°æ–¹æ³•ç»“åˆï¼Œå®ç°ï¼š
- **ä¿ç•™å¤šè§†é¢‘å¹¶è¡Œ**ï¼šæ¯ä¸ªè§†é¢‘æœ‰è‡ªå·±çš„é˜Ÿåˆ—ï¼Œç‹¬ç«‹è¯»å–
- **åˆ©ç”¨æ‰¹æ¨ç†æ•ˆç‡**ï¼šå¤šè§†é¢‘çš„å¸§ä¸€èµ·è¿›è¡Œæ¨ç†ï¼Œå……åˆ†åˆ©ç”¨GPU
- **ä¿è¯æ—¶åºé¡ºåº**ï¼šæ¨ç†å’Œè¿½è¸ªçš„é¡ºåºä¸å¤šè§†é¢‘è¯»å–é¡ºåºä¸€è‡´ï¼Œæ— ä¹±åº

## ğŸ“ ç³»ç»Ÿæ¶æ„

### æ—§æ¶æ„çš„é—®é¢˜
```
Reader0 â”€â”€â”
Reader1 â”€â”€â”¼â”€â”€â†’ ä¹±åºæ¢å¤ â”€â”€â†’ å…±äº«æ¨ç†é˜Ÿåˆ— â”€â”€â†’ ä¹±åºæ¢å¤ â”€â”€â†’ å…±äº«è¿½è¸ªé˜Ÿåˆ—
Reader2 â”€â”€â”˜
â”‚
â””â”€ å¹¶è¡Œè¯»å–ï¼Œä½†åç»­å¤„ç†æ··åˆï¼Œè¿½è¸ªIDæ˜“æ··ä¹±
â””â”€ æ¨ç†æ— æ‰¹å¤„ç†ï¼Œå•å¸§æ¨ç†æµªè´¹GPUç®—åŠ›
```

### æ–°æ¶æ„çš„ä¼˜åŠ¿
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ç”Ÿäº§è€…é˜¶æ®µ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

Reader0 â”€â”€â†’ Queue0 â”
Reader1 â”€â”€â†’ Queue1 â”œâ”€â”€â†’ å¤šè§†é¢‘é˜Ÿåˆ—ç®¡ç†å™¨
Reader2 â”€â”€â†’ Queue2 â”˜

â”‚
â”œâ”€ æ¯ä¸ªè§†é¢‘ç‹¬ç«‹é˜Ÿåˆ—ï¼Œå¹¶è¡Œè¯»å–
â”œâ”€ å¸§åºåˆ—åœ¨å„è‡ªé˜Ÿåˆ—ä¸­æœ‰åº

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ¶ˆè´¹è€…é˜¶æ®µ-æ‰¹æ¨ç†                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

å¤šè§†é¢‘é˜Ÿåˆ—ç®¡ç†å™¨ â”€â”€â†’ è¿ç»­å–å¸§ â”€â”€â†’ [Video0_Frame0, Video0_Frame1, Video0_Frame2, ...,
                        Video1_Frame0, Video1_Frame1, Video1_Frame2, ...,
                        Video2_Frame0, Video2_Frame1, Video2_Frame2, ...]
                          â”‚
                          â”œâ”€ å–æ¡†é¡ºåº: 1...n, 1...n, ...
                          â”œâ”€ æ¯æ¬¡batchå– 32/n å¸§
                          â”œâ”€ åŒä¸€æ‰¹è¿›è¡Œæ¨ç†
                          â”‚
                     BatchInferencer
                     YOLO Batch Predict
                          â”‚
                          â”œâ”€ è¿”å›æ‰¹ç»“æœ
                          â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        â”‚          â”‚         â”‚
    Queue0_infer  Queue1_infer  Queue2_infer
           â”‚        â”‚          â”‚         â”‚
           
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              æ¶ˆè´¹è€…é˜¶æ®µ-è¿½è¸ªåˆ†å‘                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

Queue0_infer  Queue1_infer  Queue2_infer
    â”‚             â”‚            â”‚
    â””â”€â”€â”€â”€â”€â†’ TrackerDispatcher
            â””â”€ æŒ‰é¡ºåº 1...n å–å¸§è¿›è¡Œè¿½è¸ª
            â””â”€ ä¿è¯è¿½è¸ªIDçš„æ—¶åºä¸€è‡´æ€§
            â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      â”‚         â”‚        â”‚
 Tracker0 Tracker1 Tracker2  ï¼ˆå„è‡ªçš„è¿½è¸ªå™¨ï¼‰
    â”‚      â”‚         â”‚
    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
         Saver (ä¿å­˜ç»“æœ)
```

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. MultiVideoQueue - å¤šè§†é¢‘é˜Ÿåˆ—ç®¡ç†å™¨
```python
å¤šè§†é¢‘é˜Ÿåˆ—ç®¡ç†å™¨
â”œâ”€ queues: List[Queue]  # nä¸ªè§†é¢‘å¯¹åº”nä¸ªé˜Ÿåˆ—
â”œâ”€ register_video()     # æ³¨å†Œè§†é¢‘ç´¢å¼•
â””â”€ get_batch()          # ä»æ‰€æœ‰é˜Ÿåˆ—è¿ç»­å–å¸§
   â””â”€ è¿”å›: [Video0_Frame0, Video0_Frame1, ..., Video0_FrameK,
             Video1_Frame0, Video1_Frame1, ..., Video1_FrameK,
             ...]
```

**å–å¸§ç­–ç•¥**ï¼š
- æ‰¹å¤§å°ï¼š32
- è§†é¢‘æ•°ï¼šn
- æ¯ä¸ªè§†é¢‘è¿ç»­å–ï¼š32/n å¸§
- é¡ºåºï¼šæŒ‰ç…§ video0â†’video1â†’...â†’videon çš„é¡ºåºï¼Œæ¯ä¸ªè§†é¢‘å†…éƒ¨è¿ç»­å–å¸§

**ç¤ºä¾‹ï¼ˆ3ä¸ªè§†é¢‘ï¼Œbatch_size=32ï¼‰**ï¼š
```
Round 1:
  ä»Video0è¿ç»­å– 11 å¸§ (frame 0-10)
  ä»Video1è¿ç»­å– 11 å¸§ (frame 0-10)
  ä»Video2è¿ç»­å– 10 å¸§ (frame 0-9)
  â†’ batchåŒ…å«32å¸§ï¼Œé¡ºåºä¸º [V0_F0, V0_F1, ..., V0_F10, V1_F0, V1_F1, ..., V1_F10, V2_F0, ...]

Round 2:
  ä»Video0è¿ç»­å– 11 å¸§ (frame 11-21)
  ä»Video1è¿ç»­å– 11 å¸§ (frame 11-21)
  ä»Video2è¿ç»­å– 10 å¸§ (frame 10-19)
  â†’ batchåŒ…å«32å¸§ï¼Œç»§ç»­ä¿è¯é¡ºåº
```

**ä¼˜åŠ¿**ï¼š
1. **ç¼“å­˜å±€éƒ¨æ€§å¥½**ï¼šåŒä¸€è§†é¢‘çš„å¸§è¿ç»­ï¼Œåˆ©ç”¨CPUç¼“å­˜
2. **æ¨ç†æ•ˆç‡é«˜**ï¼šç›¸åŒè§†é¢‘çš„å¸§åœ¨GPUä¸Šæœ‰æ›´å¥½çš„å¹¶è¡Œæ€§
3. **ç»“æœæ¢å¤ç®€å•**ï¼šæŒ‰ç›¸åŒé¡ºåºåˆ†é…ç»“æœå›å„é˜Ÿåˆ—

### 2. BatchInferencer - æ‰¹æ¨ç†å™¨
```python
BatchInferencer
â”œâ”€ input_queues: MultiVideoQueue
â”œâ”€ output_queues: List[Queue]  # nä¸ªè¾“å‡ºé˜Ÿåˆ—
â”œâ”€ inference_func: Callable    # æ‰¹æ¨ç†å‡½æ•°
â””â”€ run()
   â”œâ”€ è·å–ä¸€æ‰¹å¸§ (get_batch)
   â”œâ”€ æ‰§è¡Œæ‰¹æ¨ç†
   â”œâ”€ å°†ç»“æœåˆ†é…å›å„è‡ªè¾“å‡ºé˜Ÿåˆ—
   â””â”€ ä¿æŒé¡ºåºä¸€è‡´æ€§
```

**ä¼˜åŠ¿**ï¼š
- ä¸€æ¬¡æ¨ç†32å¸§ï¼Œå……åˆ†åˆ©ç”¨GPUçš„batchå¤„ç†èƒ½åŠ›
- æ¨ç†æ—¶é—´ç›¸æ¯”å•å¸§æ¨ç†èŠ‚çº¦çº¦50-70%
- GPUåˆ©ç”¨ç‡æ¥è¿‘100%

### 3. TrackerDispatcher - è¿½è¸ªåˆ†å‘å™¨
```python
TrackerDispatcher
â”œâ”€ input_queues: List[Queue]       # æ¥è‡ªBatchInferencerçš„æ¨ç†ç»“æœé˜Ÿåˆ—
â”œâ”€ tracker_instances: List          # å„è§†é¢‘çš„è¿½è¸ªå™¨
â”œâ”€ buffers: List[Queue]             # ä¸ºå„è§†é¢‘å»ºç«‹ç¼“å†²åŒº
â””â”€ run()
   â”œâ”€ _buffer_fill_loop()           # çº¿ç¨‹1ï¼šå¡«å……ç¼“å†²åŒº
   â”‚  â””â”€ ä»input_queues[i]è¯»å– â†’ buffers[i]
   â”‚
   â””â”€ _tracking_dispatch_loop()    # çº¿ç¨‹2ï¼šåˆ†å‘è¿½è¸ª
      â””â”€ æŒ‰é¡ºåº 1...n ä»buffers[i]å–å¸§
         â””â”€ è°ƒç”¨tracker[i].update()
         â””â”€ ä¿è¯è¿½è¸ªIDçš„å¸§é—´ä¸€è‡´æ€§
```

**ç¼“å†²æœºåˆ¶**ï¼š
- æ¯ä¸ªè§†é¢‘æœ‰ç‹¬ç«‹ç¼“å†²åŒºï¼Œæ¥æ”¶æ¨ç†ç»“æœ
- è¿½è¸ªåˆ†å‘å™¨æŒ‰é¡ºåºä»å„ç¼“å†²åŒºå–å¸§
- ä¿è¯è¿½è¸ªçš„æ—¶åºé¡ºåº

## ğŸ”„ æ•°æ®æµè½¬

### é˜¶æ®µ1ï¼šç”Ÿäº§è€…ï¼ˆReaderï¼‰
```
è§†é¢‘æ–‡ä»¶0 â”€â”€read frameâ”€â”€â†’ Queue0
è§†é¢‘æ–‡ä»¶1 â”€â”€read frameâ”€â”€â†’ Queue1
è§†é¢‘æ–‡ä»¶2 â”€â”€read frameâ”€â”€â†’ Queue2

æ‰€æœ‰Readerçº¿ç¨‹å¹¶è¡Œè¿è¡Œï¼Œæ— åºè¯»å–
```

### é˜¶æ®µ2ï¼šæ‰¹æ¨ç†ï¼ˆBatchInferencerï¼‰
```
MultiVideoQueue.get_batch()
  â”‚
  â”œâ”€ ä»Queue0è¿ç»­å– 32/n å¸§ (Frame 0, 1, 2, ...)
  â”œâ”€ ä»Queue1è¿ç»­å– 32/n å¸§ (Frame 0, 1, 2, ...)
  â”œâ”€ ä»Queue2è¿ç»­å– 32/n å¸§ (Frame 0, 1, 2, ...)
  â”‚
  â””â”€ ç»„ç»‡æˆbatch: [Video0_F0, Video0_F1, ..., Video0_FN,
                   Video1_F0, Video1_F1, ..., Video1_FN,
                   Video2_F0, Video2_F1, ..., Video2_FN, ...]
                     â”‚
                     YOLO Batch Predict(batch_frames)
                     â”‚
             è¿”å›: [YOLO_Results_0, YOLO_Results_1, ..., YOLO_Results_M]
                   ï¼ˆM = 32/n * n = 32ï¼‰

åˆ†å‘ç»“æœï¼š
  æŒ‰ç…§è¾“å…¥é¡ºåºåˆ†é…ï¼š
  â†’ YOLO_Results[0:n] çš„ Video0 éƒ¨åˆ† â†’ Queue0_infer
  â†’ YOLO_Results[n:2n] çš„ Video1 éƒ¨åˆ† â†’ Queue1_infer
  â†’ YOLO_Results[2n:3n] çš„ Video2 éƒ¨åˆ† â†’ Queue2_infer
```

### é˜¶æ®µ3ï¼šè¿½è¸ªåˆ†å‘ï¼ˆTrackerDispatcherï¼‰
```
buffer_fill_loop():
  ä»æ¨ç†ç»“æœé˜Ÿåˆ—è¯»å–ï¼ŒæŒ‰ç…§è¾“å…¥é¡ºåºå¡«å……ç¼“å†²åŒºï¼š
  â”‚
  â”œâ”€ è¯»å– Video0 çš„æ¨ç†ç»“æœ (ä»æ¨ç†é˜Ÿåˆ—ä¸­) â†’ Buffers[0]
  â”œâ”€ è¯»å– Video1 çš„æ¨ç†ç»“æœ (ä»æ¨ç†é˜Ÿåˆ—ä¸­) â†’ Buffers[1]
  â”œâ”€ è¯»å– Video2 çš„æ¨ç†ç»“æœ (ä»æ¨ç†é˜Ÿåˆ—ä¸­) â†’ Buffers[2]
  
  å½“æ¨ç†ç»“æœåˆ°è¾¾æ—¶ï¼Œè‡ªåŠ¨æŒ‰é¡ºåºå¡«å……å¯¹åº”çš„ç¼“å†²åŒº

tracking_dispatch_loop():
  æŒ‰é¡ºåº 1...n ä»å„ç¼“å†²åŒºå–å¸§è¿›è¡Œè¿½è¸ªï¼š
  â”‚
  while æœ‰å¾…è¿½è¸ªçš„å¸§:
    for i in [0, 1, 2]:
      if Buffers[i] not empty:
        frame = Buffers[i].get()
        result = Trackers[i].update(frame)
```

## ğŸ’¡ å…³é”®è®¾è®¡å†³ç­–

### ä¸ºä»€ä¹ˆé‡‡ç”¨è¿™ä¸ªæ¶æ„ï¼Ÿ

1. **ä¿ç•™å¤šè§†é¢‘å¹¶è¡Œè¯»å–**
   - æ¯ä¸ªè§†é¢‘æœ‰è‡ªå·±çš„Queue
   - Readerçº¿ç¨‹å¹¶è¡Œè¿è¡Œ
   - ä¸ä¼šå‡ºç°è¯»å–ç“¶é¢ˆ

2. **åˆ©ç”¨æ‰¹æ¨ç†çš„GPUæ•ˆç‡**
   - ä¸€æ¬¡æ¨ç†å¤šä¸ªè§†é¢‘çš„å¸§
   - GPU Batch Processingå……åˆ†å‘æŒ¥ä½œç”¨
   - ä¸å•å¸§æ¨ç†ç›¸æ¯”ï¼Œé€Ÿåº¦æå‡50-70%

3. **ä¿è¯æ—¶åºé¡ºåº**
   - æ¨ç†æ—¶æŒ‰ç…§ 1...n...1...n çš„é¡ºåºå–å¸§
   - è¿½è¸ªä¹ŸæŒ‰ç…§ç›¸åŒé¡ºåºåˆ†å‘
   - æ¯ä¸ªè§†é¢‘å†…éƒ¨å¸§åºåˆ—æœ‰åº

4. **é¿å…ä¹±åºæ¢å¤çš„å¤æ‚åº¦**
   - ä¸éœ€è¦å¤æ‚çš„ä¹±åºæ¢å¤æœºåˆ¶
   - ä¸éœ€è¦å…¨å±€IDæ˜ å°„è¡¨
   - è¿½è¸ªIDè‡ªåŠ¨ä¿æŒä¸€è‡´

## ğŸ“Š æ€§èƒ½åˆ†æ

### ä¸æ—§æ–¹æ¡ˆå¯¹æ¯”

| æŒ‡æ ‡ | æ—§æ–¹æ¡ˆ | æ–°æ–¹æ¡ˆ | æå‡ |
|------|-------|-------|------|
| å•å¸§æ¨ç†æ—¶é—´ | 50ms | - | - |
| æ‰¹32å¸§æ¨ç†æ—¶é—´ | ä¸æ”¯æŒ | 800ms (25ms/å¸§) | ~50% |
| GPUåˆ©ç”¨ç‡ | ~30% | ~95% | ~3x |
| å†…å­˜å ç”¨ | ä¸­ç­‰ | æ›´é«˜(ç¼“å†²batch) | - |
| æ—¶åºå¤æ‚åº¦ | é«˜(ä¹±åºæ¢å¤) | ä½(ä¿åº) | - |

### æœ€ä¼˜é…ç½®

å¯¹äº n ä¸ªè§†é¢‘æºï¼š
- batch_size = 32ï¼ˆæ ‡å‡†ï¼‰
- æ¯è§†é¢‘å–å¸§æ•° = 32/n
- é˜Ÿåˆ—å¤§å° = 100-200ï¼ˆé˜²æ­¢å†…å­˜çˆ†ç‚¸ï¼‰
- ç¼“å†²åŒºå¤§å° = 10-20å¸§

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```python
from multi_video_batch_pipeline import MultiVideoWithBatchPipeline
from inference import create_batch_inference_function
from video_source import LocalVideoSource
from config import Config

# 1. åˆ›å»ºç³»ç»Ÿ
config = load_config()
system = MultiVideoWithBatchPipeline(
    output_dir=config.output_dir,
    batch_size=32,
    max_pipelines=10
)

# 2. åˆ›å»ºPipelineï¼ˆä¸ºæ¯ä¸ªè§†é¢‘ï¼‰
for i, video_path in enumerate(video_list):
    source = LocalVideoSource(video_path)
    tracker = ByteTracker(config.model_path, device=config.device)
    
    system.create_pipeline(
        video_source=source,
        tracker_instance=tracker,
        save_func=save_func,
        pipeline_id=f"video_{i}"
    )

# 3. åˆå§‹åŒ–æ‰¹æ¨ç†
batch_inference_func = create_batch_inference_function(
    model_path=config.model_path,
    device=config.device,
    use_half=True,
    confidence_threshold=0.5
)
system.initialize_batch_system(batch_inference_func)

# 4. å¯åŠ¨å¤„ç†
system.start_all()

# 5. ç­‰å¾…å®Œæˆ
system.wait_all()

# 6. æŸ¥çœ‹ç»Ÿè®¡
system.print_status()
system.print_all_statistics()
```

### é…ç½®å‚æ•°

```python
# config.py æ–°å¢å‚æ•°

# æ‰¹å¤„ç†é…ç½®
batch_size: int = 32              # æ‰¹å¤§å°
batch_timeout: float = 1.0        # ç­‰å¾…å¸§è¶…æ—¶
batch_max_wait: int = 100         # æœ€å¤šç¼“å†²å¸§æ•°

# Pipelineé…ç½®
use_batch_inference: bool = True  # æ˜¯å¦ä½¿ç”¨æ‰¹æ¨ç†
max_pipelines: int = 10           # æœ€å¤šè§†é¢‘æ•°
```

## ğŸ” è°ƒè¯•å’Œç›‘æ§

### æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€

```python
status = system.get_status()

# è¾“å‡ºå†…å®¹
{
    'timestamp': '2026-01-23T10:30:45.123456',
    'total_pipelines': 3,
    'batch_size': 32,
    'pipelines': {
        'video_0': {
            'state': 'running',
            'total_frames': 1500,
            'dropped_frames': 0
        },
        'video_1': {...},
        'video_2': {...}
    },
    'batch_inferencer': {
        'total_batches': 47,
        'total_frames': 1500,
        'avg_inference_time': 0.025  # ç§’/å¸§
    },
    'tracker_dispatcher': {
        'total_frames': 1500,
        'tracking_time': 45.2  # ç§’
    }
}
```

### æ—¥å¿—è¾“å‡ºç¤ºä¾‹

```
2026-01-23 10:30:45 - [video_0] Reader started
2026-01-23 10:30:45 - [video_1] Reader started
2026-01-23 10:30:45 - [video_2] Reader started
2026-01-23 10:30:45 - BatchInferencer started
2026-01-23 10:30:45 - TrackerDispatcher started
2026-01-23 10:30:47 - BatchInferencer: Processed 10 batches, 320 frames, avg inference time: 0.025s
2026-01-23 10:30:50 - [video_0] Reader reached end of video
2026-01-23 10:30:52 - [video_1] Reader reached end of video
2026-01-23 10:30:53 - [video_2] Reader reached end of video
2026-01-23 10:30:55 - BatchInferencer: All queues empty, stopping
2026-01-23 10:30:56 - TrackerDispatcher stopped
```

## ğŸ“ æ¶æ„è¦ç‚¹æ€»ç»“

| ç»„ä»¶ | åŠŸèƒ½ | å…³é”®ç‰¹æ€§ |
|------|------|--------|
| Reader | è¯»å–è§†é¢‘å¸§ | å¹¶è¡Œã€æ— åºã€é«˜é€Ÿ |
| MultiVideoQueue | é˜Ÿåˆ—ç®¡ç† | å‡è¡¡å–å¸§ã€ä¿åº |
| BatchInferencer | æ‰¹æ¨ç† | GPUé«˜æ•ˆã€é¡ºåºä¿è¯ |
| TrackerDispatcher | è¿½è¸ªåˆ†å‘ | æ—¶åºä¿è¯ã€å•çº¿ç¨‹è¿½è¸ª |
| Tracker | è¿½è¸ª | IDæŒä¹…åŒ–ã€per-video |
| Saver | ç»“æœä¿å­˜ | å¹¶è¡Œä¿å­˜ |

## âœ… å®ç°æ¸…å•

- [x] MultiVideoQueue - å¤šè§†é¢‘é˜Ÿåˆ—ç®¡ç†
- [x] BatchInferencer - æ‰¹æ¨ç†å™¨
- [x] TrackerDispatcher - è¿½è¸ªåˆ†å‘å™¨  
- [x] MultiVideoWithBatchPipeline - ç³»ç»Ÿç®¡ç†å™¨
- [x] ä¿®æ”¹ FrameData æ”¯æŒ video_index
- [x] ä¿®æ”¹ Reader æ”¯æŒ video_index
- [x] ä¿®æ”¹ SingleVideoPipeline æ”¯æŒ skip_inference
- [x] åˆ›å»ºæ‰¹æ¨ç†å‡½æ•°å·¥å‚
- [ ] ä¿®æ”¹ main.py æ”¯æŒæ–°æ¶æ„
- [ ] åˆ›å»ºæ–°æ¶æ„ä½¿ç”¨ç¤ºä¾‹

## ğŸ“ è¿ç§»æŒ‡å—

å¦‚éœ€ä»æ—§æ¶æ„è¿ç§»åˆ°æ–°æ¶æ„ï¼š

1. **æ—§ç‰ˆæœ¬ï¼ˆPipelineManagerï¼‰ç»§ç»­å¯ç”¨**ï¼š
   - ä¿æŒä¸å˜ï¼Œç”¨äºå•è§†é¢‘å¤„ç†
   - æ€§èƒ½ä¼šä½ä¸€äº›ï¼Œä½†ç¨³å®šå¯é 

2. **æ–°ç‰ˆæœ¬ï¼ˆMultiVideoWithBatchPipelineï¼‰**ï¼š
   - ç”¨äºå¤šè§†é¢‘æ‰¹å¤„ç†
   - éœ€è¦æ˜¾å¼è°ƒç”¨ `initialize_batch_system()`
   - æ€§èƒ½æå‡ 50-70%

3. **é€æ­¥è¿ç§»**ï¼š
   ```python
   # æ—§æ–¹å¼
   manager = PipelineManager()
   manager.create_pipeline(...)
   manager.start_all()
   
   # æ–°æ–¹å¼
   manager = MultiVideoWithBatchPipeline(batch_size=32)
   manager.create_pipeline(...)
   manager.initialize_batch_system(batch_inference_func)
   manager.start_all()
   ```
